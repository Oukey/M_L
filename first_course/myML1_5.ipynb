{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myML1_5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oukey/M_L/blob/master/myML1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcgW51u1yP8C",
        "colab_type": "text"
      },
      "source": [
        "# **Занятие 5. Классификация изображений**\n",
        "\n",
        "https://vk.com/lambda_brain\n",
        "\n",
        "Классификация изображений -- это уже полноценная задача реального мира. Самое приятное здесь в том, что нету качественного алгоритмического отличия классификации изображений от классификации других наборов данных. Нейронные сети работают таким магическим образом, что мы просто подаём им на вход наборы \"байтов\", и не важно, что это -- абстрактные значения функций или пикселы изображений, они все анализируются нейросетью по единой схеме.\n",
        "\n",
        "Мы познакомимся с основными принципами классификации изображений в PyTorch, а также изучим смежные вопросы, связанные с загрузкой объёмных датасетов с изображениями в программу и их удобной визуализацией.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls8BPtFn0Uop",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ssFltrylmg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "В качестве первого примера воспользуемся распространённым датасетом изображений **MNIST**, на котором создано наверное максимальное количество обучающих уроков по нейронным сетям.\n",
        "\n",
        "MNIST подготовлен **Яном ЛеКуном** -- ведущим мировым специалистом по нейронным сетям, и представляет собой датасет для обучения распознаванию рукописных цифр. Обучающая выборка содержит 60,000 изображений, и тестовая -- 10,000. Каждое изображение чёрно-белое размером 28x28 пикселов.\n",
        "\n",
        "Импортируем нужные модули:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8abpHoRq6V-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGDiRyHTy4kF",
        "colab_type": "text"
      },
      "source": [
        "Задаём гипер-параметры:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfwVbruB8gQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_size = 28*28     # Размер изображения в точках\n",
        "hidden_size = 500      # Количество нейронов в скрытом слое\n",
        "num_classes = 10       # Количество распознающихся классов (10 цифр)\n",
        "n_epochs = 2           # Количество эпох\n",
        "batch_size = 4         # Размер мини-пакета входных данных\n",
        "lr = 0.01              # Скорость обучения"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvCFT8OvzLik",
        "colab_type": "text"
      },
      "source": [
        "Большое количество готовых датасетов и различные удобные методы их загрузки и обработки собраны в модуле torchvision. Имеется в нём конечно и MNIST.\n",
        "\n",
        "В конструкторе датасета MNIST указывается, как правило, каталог root, где будет локально размещён соответствующий датасет, download -- необходимость скачивания датасета для его локального использования, train -- признак, является ли данный датасет обучающим или тестовым, и трансформация transform, которую надо выполнить над данным датасетом. Последняя фича весьма полезна, потому что исходные изображения нередко требуется предварительно обрабатывать под конкретный формат их дальнейшего анализа. В нашем случае просто укажем стандартную трансформацию преобразования входных данных в тензоры.\n",
        "\n",
        "Убедимся, что размеры датасета совпадают с официально объявленными.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eX2jdtCLzWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "mnist_trainset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_testset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "print(len(mnist_trainset))\n",
        "print(len(mnist_testset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Wg4nsIzpkF",
        "colab_type": "text"
      },
      "source": [
        "Так как наш датасет большой по размеру, обрабатывать его надо небольшими порциями, мини-пакетами, как рассказывалось во втором занятии -- с помощью загрузчиков данных DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brvDSwBVNqqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=mnist_trainset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True) # загрузчик обучающих данных\n",
        "test_loader = torch.utils.data.DataLoader(dataset=mnist_testset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False) # загрузчик тестовых данных"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHdERlgdz2dG",
        "colab_type": "text"
      },
      "source": [
        "Добавим наш стандартный шаг обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBltxfGOChj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# импортируем нужные библиотеки\n",
        "import torch\n",
        "import numpy as np # всегда пригодится :)\n",
        "from torch.nn import Linear, Sigmoid\n",
        "\n",
        "# инициализируем девайс\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# добавляем типовую функцию \"шаг обучения\"\n",
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    def train_step(x, y):\n",
        "        model.train()\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        return loss.item()\n",
        "    return train_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmngiGejz5lW",
        "colab_type": "text"
      },
      "source": [
        "Структура нашей модели будет представлять собой двуслойную нейронную сеть -- она ничем не отличается от модели, применявшейся в прошлом занятии при анализе абстрактного датасета (линейный вход + ReLU + линейный выход).\n",
        "\n",
        "Воспользуемся лоссом CrossEntropyLoss() и методом оптимизации Adam.\n",
        "\n",
        "Обратите внимание, что мы задаём уже не тысячи, а **всего две эпохи** -- процесс обучения на таком довольно объёмном датасете потребует уже прилично времени (несколько минут на одну эпоху).\n",
        "\n",
        "Единственное дополнение -- мы применяем метод reshape(-1, 28 * 28), чтобы изменить входной трёхмерный формат изображения 1x28x28 (глубина цветности x размеры) на нужный нам одномерный вектор длиной 784 значения. Параметр -1 означает, что преобразование выполняется в одномерный результат.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlW-CkjeOn2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim, nn\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, num_classes))\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  \n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        loss = train_step(images, labels)\n",
        "    print(epoch)\n",
        "\n",
        "print(model.state_dict())    \n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpV9EAsF0mK8",
        "colab_type": "text"
      },
      "source": [
        "Теперь проверим, с какой точностью наша модель проверит 10,000 тестовых изображений:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-zC19n5X_-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Точность: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRRn3tq00-s",
        "colab_type": "text"
      },
      "source": [
        "Около 90% -- это очень хороший результат для тренировки всего в течение пяти минут за две эпохи. Обратите внимание, что обученная модель время на распознавание даже такого приличного по объёму датасета уже практически не тратит.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Вычисление, конечно, может занимать не минуты, а часы, сутки, недели и месяцы работы. Чтобы продолжить работу с нашей обученной моделью уже в прикладных задачах, нам надо прежде всего её сохранить в файле (в PyTorch принято, что расширение файла с полностью сохранённой моделью -- .pt).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NXf2S6EY8PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, 'mnist_full.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MgEmnMa1CzC",
        "colab_type": "text"
      },
      "source": [
        "Сохранение выполняется в виртуальной машине гугла, где мы загрузили датасет MNIST. Загрузка модели выполняется так же просто:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjjzYGrHjHlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(\"mnist_full.pt\")\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7uotPWL1KwL",
        "colab_type": "text"
      },
      "source": [
        "После загрузки модели надо обязательно выполнить её метод **eval()** -- это означает, что мы будем пользоваться моделью в режиме её эксплуатации, а не в режимах обучения или каких-то других. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u12egQ-g1TAK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Наконец, в заключение проверим результаты работы нашей обученной модели визуально. Запомните этот типовой код, его удобно применять в самых разных задачах классификации изображений. Он выводит четыре случайных изображения из датасета и указывает под ними соответствующие им классы (прогноз), которые заданы в списке classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BaXz8DnY-ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join('%10s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BVbpWvHQ1F2",
        "colab_type": "text"
      },
      "source": [
        "##**Задание**\n",
        "\n",
        "Попробуйте повысить точность нашей модели:\n",
        "\n",
        "* увеличьте количество эпох;\n",
        "* увеличьте количество нейронов;\n",
        "* добавьте новые скрытые слои;\n",
        "* измените размер мини-пакета.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9JkYrdVE3bb",
        "colab_type": "text"
      },
      "source": [
        "Далее мы рассмотрим работу с более сложным датасетом изображений (котики и пёсики), которому потребуется предварительная обработка."
      ]
    }
  ]
}
