{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myML1_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oukey/M_L/blob/master/myML1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqFyzPDuFDvI",
        "colab_type": "text"
      },
      "source": [
        "#**Первое занятие по PyTorch**\n",
        "\n",
        "Изучаем основные понятия и три ключевых пакета PyTorch, разбираемся, как формируется стандартный, универсальный алгоритм построения и анализа модели.\n",
        "\n",
        "Этот алгоритм вы сможете сразу использовать для проверки самых разных гипотез.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI4Zv-dtka20",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*Дискламер: местами будут использоваться явные англицизмы -- чтобы быть в курсе, довольно часто они используются в тематических обсуждениях на русскоязычных форумах, и более компактны и наглядны.*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Параллельно очень рекомендую к прочтению эту серию статей (перевод книги Майкла Нильсена \"Neural Networks and Deep Learning\")**\n",
        "https://habr.com/ru/post/463171/\n",
        "\n",
        "В ней подробно рассматривается вся базовая теория нейронных сетей и глубокого обучения.\n",
        "\n",
        "---\n",
        "\n",
        "##**Простая линейная регрессия**\n",
        "\n",
        "Есть простая линейная функция,  \n",
        "\n",
        "`y = 1 + 2 * x + шум`\n",
        "\n",
        "которая в контексте машинного обучения трактуется как прогнозирование некоторых результатов. \n",
        "\n",
        "x -- это **входные данные, признаки (features)**;\n",
        "y -- это **прогноз**.\n",
        "\n",
        "Например, если автомобиль едет с линейной скоростью, то пройденное им расстояние зависит от времени езды. В данных из реальной жизни в такой зависимости всегда будет шум -- скорость всё время немножечко плавает, возможны остановки на светофорах и т. д.\n",
        "\n",
        "Принципиальный момент. Чем вообще мы занимаемся?\n",
        "\n",
        "В нашей функции есть два коэффициента 1 и 2, или в общем случае\n",
        "\n",
        "`y = a + b * x`\n",
        "\n",
        "это коэффициенты (**параметры**) a и b, которые ещё называются **метки (labels)**.\n",
        "\n",
        "Про наши данные (например, набор пар значений \"время - расстояние\") мы знаем только, что они с большой вероятностью моделируются подобной линейной регрессией. То есть то, что нам надо найти -- это такие a и b, что соответствующая функция будет выдавать значения, как можно более близкие к обучающим.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25-CG5zmmtya",
        "colab_type": "text"
      },
      "source": [
        "##**Немного теории: градиентный спуск**\n",
        "\n",
        "**Градиент (gradient)** -- это частная производная (производная по одной  конкретной переменной).\n",
        "\n",
        "*Кто не помнит школьный курс математики, производная -- это просто скорость изменения чего-то. Например, если вы едете с фиксированной скоростью, она не меняется, то и производная её (ускорение) будет равно нулю. А если скорость всё время растёт, то и градиент (ускорение) будет больше нуля, и тем он будет больше, чем сильнее увеличивается скорость.*\n",
        "\n",
        "В общем случае модель включает в себя множество параметров (скорость автомобиля -- это функция от множества критериев), и градиент показывает, как сильно меняется (со временем например) какой-то один конкретный параметр (считаем частную производную по этому параметру), подразумевая, что остальные если и меняются, то незначительно.\n",
        "\n",
        "**Лосс (loss)** -- ошибка, погрешность (например, среднеквадратическая ошибка).\n",
        "\n",
        "Оптимизационный механизм, отыскивающий нужные нам коэффициенты, называется \"**градиентный спуск**\" (подобных алгоритмов много). Его работа складывается из четырёх шагов.\n",
        "\n",
        "1) считаем лосс (стратегически стремимся к его минимизации).\n",
        "\n",
        "2) вычисляем градиенты. \n",
        "\n",
        "У нас в модели, как уже говорилось, есть два параметра a и b, для которых мы должны считать градиенты. Мы хотим определить, как будет меняться лосс при изменении каждого из этих параметров.\n",
        "\n",
        "3) обновляем параметры. Так как мы хотим минимизировать лосс, то градиенты берутся с обратным знаком, и учитывается также коэффициент скорости обучения.\n",
        "\n",
        "**Скорость обучения (learning rate)** -- некоторый коэффициент, который учитывается при изменении параметров в градиентном спуске.\n",
        "\n",
        "4) при необходимости проверяем что получилось, и переходим к п.1.\n",
        "\n",
        "Такой цикл из четырёх шагов называется **эпоха (epoch)**.\n",
        "Эпоха -- один цикл оптимизации (например, шаг градиентного спуска), когда была пересчитана каждая точка выборки.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZht9-DMpNmk",
        "colab_type": "text"
      },
      "source": [
        "##**Градиентный спуск на базе NumPy**\n",
        "\n",
        "Реализуем сперва градиентный спуск классическим способом: только с помощью стандартной библиотеки численных методов NumPy.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL87rRR0TJeE",
        "colab_type": "text"
      },
      "source": [
        "Подробное введение в линейную алгебру и NumPy для начинающих:\n",
        "\n",
        "https://github.com/DLSchool/dlschool/tree/master/02.%20Linear%20Algebra%2C%20Numpy\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsd8wI9uUVDY",
        "colab_type": "text"
      },
      "source": [
        "Введение в Matplotlib (рисуем графики):\n",
        "\n",
        "https://github.com/DLSchool/dlschool/tree/master/03.%20Pandas%2C%20Matplotlib%2C%20ML%20basics\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1_wBE0WU1Z8",
        "colab_type": "text"
      },
      "source": [
        "Введение в линейные модели и градиентный спуск: (*нужно подправить ссылку!!!*)\n",
        "\n",
        "https://github.com/DLSchool/dlschool/tree/master/03.%20Pandas%2C%20Matplotlib%2C%20ML%20basics\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsY44JTKBhQA",
        "colab_type": "code",
        "outputId": "6ab74dcc-f696-4860-8294-c601e0f13b10",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "# \n",
        "# оригинал\n",
        "# https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# инициализация повторяемой последовательности случайных чисел\n",
        "np.random.seed(42) \n",
        "\n",
        "# создаём np-массив из 100 случайных чисел в диапазоне 0..1\n",
        "sz = 100\n",
        "x = np.random.rand(sz, 1) \n",
        "\n",
        "# строим функцию y = f(x) и добавляем немного гауссова шума\n",
        "y = 1 + 2 * x + 0.1 * np.random.randn(sz, 1) \n",
        "\n",
        "# формируем индексы от 0 до 99 \n",
        "idx = np.arange(sz)\n",
        "# случайно их тасуем\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "\n",
        "# первые 80 случайных индексов (значений x) используем для обучения\n",
        "sz80 = int(sz*0.8)\n",
        "train_idx = idx[: sz80]\n",
        "\n",
        "# оставшиеся 20 -- для валидации\n",
        "val_idx = idx[sz80:]\n",
        "\n",
        "# формируем наборы обучающих данных\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "# и наборы для валидации\n",
        "x_val, y_val = x[val_idx], y[val_idx]\n",
        "\n",
        "# выводим на экран\n",
        "plt.scatter(x_train, y_train) \n",
        "plt.title('Обучающая_выборка') \n",
        "plt.show()\n",
        "plt.scatter(x_val, y_val, color= \"red\") \n",
        "plt.title('Проверочная_выборка') \n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwR8RUTEJ/oiIiknwR0RUzP8Ht2csFfG3FYsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA1VF9YHUtmy",
        "colab_type": "code",
        "outputId": "e0387fb2-b4c2-4c04-8563-6e08883e5d49",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# задаём начальные случайные значения коэффициентам линейной регрессии \n",
        "a = np.random.randn(1)\n",
        "b = np.random.randn(1)\n",
        "print('случайные коэф.:', a,b)\n",
        "\n",
        "# скорость обучения\n",
        "lr = 0.1\n",
        "# количество эпох\n",
        "n_epochs = 1000\n",
        "\n",
        "# основной цикл\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "    # рассчитываем результирующий массив с текущими коэффициентами a и b\n",
        "    # на основе обучающей выборки \n",
        "    yhat = a + b * x_train\n",
        "    \n",
        "    # 1. определяем лосс\n",
        "    # сперва считаем отклонение нового результата от обучающего:\n",
        "    error = (y_train - yhat)\n",
        "    # и затем считаем среднеквадратическую ошибку:\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # 2. считаем градиенты (вспоминая формулу производной)\n",
        "    # для коэффициента a\n",
        "    a_grad = -2 * error.mean()\n",
        "    # для коэффициента b\n",
        "    b_grad = -2 * (x_train * error).mean()\n",
        "    \n",
        "    # 3. обновляем параметры, используя коэффициент скорости обучения, \n",
        "    # градиенты берём с обратным знаком\n",
        "    a = a - lr * a_grad\n",
        "    b = b - lr * b_grad\n",
        "print('расчетные коэф.:', a,b)\n",
        "print('оригинальные:', [1], [2])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "случайные коэф.: [0.49671415] [-0.1382643]\n",
            "расчетные коэф.: [1.02354094] [1.96896411]\n",
            "оригинальные: [1] [2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1qI2IV2pxyO",
        "colab_type": "text"
      },
      "source": [
        "Итак, исходные коэффициенты были очень далеки от оригинальных:\n",
        "[0.49671415] [-0.1382643]\n",
        "\n",
        "Но итоговые результаты оказались весьма близки к ним:\n",
        "[1.02354094] [1.96896411]\n",
        "\n",
        "Более того, на основании нашей случайной выборки какие-то более точные значения коэффициентов получить уже практически нельзя.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnxBhwkHp_z8",
        "colab_type": "text"
      },
      "source": [
        "##**Тензоры**\n",
        "\n",
        "В пакетах машинного обучения основная работа ведётся как правило с тензорами.\n",
        "\n",
        "**Тензор** -- это обычно вектор (одномерный массив), двумерный массив (матрица), в общем случае многомерный массив. \n",
        "\n",
        "Операции над тензорами очень эффективно выполняются графическими процессорами, поэтому библиотеки машинного обучения оптимизируются под GPU.\n",
        "\n",
        "Над тензорами возможны как обычные арифметические матричные операции, так и множество дополнительных действий. \n",
        "\n",
        "**Скаляр** -- это массив с нулём измерений, или просто одно число.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPMCGh3qVe-k",
        "colab_type": "text"
      },
      "source": [
        "Введение и практика с тензорами на PyTorch, рекомендую пройти:\n",
        "\n",
        "https://github.com/DLSchool/dlschool/blob/master/06.%20PyTorch/%5Bseminar%5Dpytorch_basics.ipynb\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hv1alqxqhmE",
        "colab_type": "text"
      },
      "source": [
        "##**Берёмся за PyTorch**\n",
        "\n",
        "В PyTorch активно применяется понятие девайса.\n",
        "\n",
        "**Девайс (device)** -- устройство, на котором обрабатываются тензоры (графический процессор или обычный).\n",
        "\n",
        "Начало работы с PyTorch обычно строится по типовому шаблону:\n",
        "\n",
        "-- проверяем, доступны ли ресурсы GPU;\n",
        "\n",
        "-- готовим наши данные, преобразовывая в формат тензоров (для массивов NumPy это функция from_numpy);\n",
        "\n",
        "-- при желании данные можно привести к типу меньшей точности (например, 32-разрядному float), чтобы сэкономить ресурсы;\n",
        "\n",
        "-- выгружаем данные на конкретный девайс (GPU или обычный процессор) с помощью функции to().\n",
        "\n",
        "Тип тензора можно получить методом type(), который вернёт, например, torch.FloatTensor, если используется обычный процессор, или torch.cuda.FloatTensor, если GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6aeaa5fZqpK",
        "colab_type": "code",
        "outputId": "bb74d871-84ec-426b-f2e2-339115bec6fe",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch # подключаем основной пакет PyTorch\n",
        "\n",
        "# стандартная команда настройки девайса на GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('device:', device)\n",
        "\n",
        "# Наши исходные данные хранятся в формате массивов NumPy, \n",
        "# требуется преобразовать их в формат тензоров PyTorch,\n",
        "# привести к типу float и выгрузить на девайс\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
        "print('type tensor: ', x_train_tensor.type())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cpu\n",
            "type tensor:  torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns0XT4uYrQ6g",
        "colab_type": "text"
      },
      "source": [
        "Теперь запрограммируем градиентный спуск, те же четыре шага, с помощью PyTorch.\n",
        "\n",
        "Сперва проинициализируем параметры (тензоры) a и b, используя случайные функции PyTorch.\n",
        "\n",
        "В параметрах функции генерации случайного значения torch.randn() в дополнение к понятным параметрам dtype (желаемый тип результирующего тензора) и целевой девайс (device), указывается очень важный requires_grad = True. Его смысл подробнее рассмотрим позже, но основная его идея в том, что он задаёт автоматическое вычисление градиента для данного тензора. Мы ведь считаем градиенты именно по этим двум параметрам a и b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwVawk-PHnVW",
        "colab_type": "code",
        "outputId": "93e8e8e8-8173-43e9-8369-60cfdbffae13",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# инициализация повторяемой посл-ти случайных чисел\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# задаём начальные случайные значения коэффициентам линейной регрессии \n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6At-XHNsAUE",
        "colab_type": "text"
      },
      "source": [
        "Мы получим такой результат: \n",
        "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
        "(значения a и b могут быть другими, в зависимости от версии PyTorch).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fMgF9nksRl8",
        "colab_type": "text"
      },
      "source": [
        "##**Autograd: автоматизируем расчёт градиентов**\n",
        "\n",
        "Autograd -- пакет автоматического дифференцирования PyTorch (один из трёх ключевых). Он очень крутой: можно забыть про частные производные, ручное программирование формул производных и многую другую математику -- теперь она скрыта под капотом autograd!\n",
        "\n",
        "https://pytorch.org/docs/stable/autograd.html?highlight=autograd#module-torch.autograd\n",
        "\n",
        "Нам теперь не нужно вручную программировать производные -- **вычисления всех градиентов выполняет универсальный метод backward()**. Так как мы вычисляем частные производные для лосса, к нему этот метод и применяем, вся магия совершится автоматически внутри него. А текущие значения градиентов мы можем получить обращением к атрибуту **grad** соответствующего тензора.\n",
        "\n",
        "Однако если далее мы захотим обновить параметры по старой схеме, появятся ошибки.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRNMuJ4dgV-I",
        "colab_type": "code",
        "outputId": "496fa9a9-2708-4372-d1ed-c4e825186839",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# скорость обучения\n",
        "lr = 0.1\n",
        "\n",
        "# количество эпох\n",
        "n_epochs = 1000 \n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "    # как и в примере с numpy, записываем нашу линейную зависимость,\n",
        "    # только теперь в качестве обучающей выборки -- тензор\n",
        "    yhat = a + b * x_train_tensor\n",
        "    \n",
        "    # 1. считаем лосс как и раньше\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    # 2. вычисляем градиенты автоматически!\n",
        "    loss.backward()\n",
        "    \n",
        "    \n",
        "    # ПЕРВАЯ ПОПЫТКА (неверно)\n",
        "    # TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'\n",
        "    # a = a - lr * a.grad\n",
        "    # b = b - lr * b.grad\n",
        "\n",
        "    # ВТОРАЯ ПОПЫТКА (неверно)\n",
        "    # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
        "    # a -= lr * a.grad\n",
        "    # b -= lr * b.grad        \n",
        "    \n",
        "    # ТРЕТЬЯ ПОПЫТКА (верно)\n",
        "    with torch.no_grad():\n",
        "        a -= lr * a.grad\n",
        "        b -= lr * b.grad\n",
        "    \n",
        "    # Обнуляем градиенты вручную\n",
        "    a.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "    \n",
        "print(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm5TTEjemt7A",
        "colab_type": "code",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRz0O8-bBuYs",
        "colab_type": "text"
      },
      "source": [
        "В первом случае мы не учли, что по умолчанию **все действия и операции над тензорами иммутабельны**. Мы формируем новые тензоры в процессе арифметических операций и при переназначении нашим параметрам их же обновлённых значений градиенты сбрасываются в начальное значение None, и возникает подобная ошибка.\n",
        "\n",
        "Нам надо выполнять обновления параметров непосредственно в них самих (**in place**) -- работать с ними как с мутабельными объектами, без создания промежуточных данных. Но и вторая попытка обновления с помощью стандартной питоновской in-place операции -= тоже выдаст ошибку.\n",
        "\n",
        "\n",
        "Дело в том, что PyTorch строит **динамический вычислительный граф** (см. далее) для каждой питоновской операции, которая прямо или косвенно связана с тензорами, для которых считаются градиенты. И чтобы временно отключить такой режим по умолчанию, надо воспользоваться методом **torch.no_grad()**, который позволяет выполнять операции над тензорами в отрыве от графа вычислений. Именно это мы и делаем в третьей попытке.\n",
        "\n",
        "\n",
        "И наконец, надо ещё учесть, что **градиенты автоматически не обнуляются, а накапливаются** -- в каждой эпохе их надо обнулять вручную. В PyTorch принято, что все методы по умолчанию иммутабельны (не воздействуют на своего родителя), а их мутабельные (in place) версии (полезные например, когда мы не хотим создавать промежуточные копии крупных объектов) отличаются символом подчёркивания в конце своего названия.\n",
        "Обнуление градиента \"на месте\" выполнит соответствующий метод **zero_()**.\n",
        "\n",
        "Итак, мы получаем итоговый результат, очень близкий к версии NumPy:\n",
        "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y67gyH5Du1A",
        "colab_type": "text"
      },
      "source": [
        "##**Динамический граф вычислений**\n",
        "\n",
        "**Вычислительный граф** -- это направленный граф, в узлах которого выполняются некоторые вычисления. \n",
        "\n",
        "Вычисления в узлах графа используют данные, которые были вычислены в \"предыдущих\" узлах.\n",
        "\n",
        "Каждый узел графа -- по сути чистая функция, получающая на вход данные от связанных с ним узлов; по этой причине исполнение вычислительного графа хорошо распараллеливается.\n",
        "\n",
        "По большому счёту, от фреймворков машинного обучения требуются три основные вещи: **формировать граф вычислений, дифференцировать его, и вычислять**.\n",
        "В PyTorch такой граф строится динамически при запуске кода, и по нему можно проходить как вперёд, от начала к концу, так и обратно, от конца в начало.\n",
        "\n",
        "Зачем же этот граф нужен, как он связан с нашим кодом, как это вообще работает?\n",
        "\n",
        "Пакет PyTorchViz содержит средства визуализации графов вычислений. Установите его:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAckCUd1j2j6",
        "colab_type": "code",
        "outputId": "dbda0763-68f3-46a9-a087-905a1a53c6dc",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8t6nPBcEI4u",
        "colab_type": "text"
      },
      "source": [
        "Подготовим минималистичный код: два тензора с поддержкой градиентов, формулу прогнозирования, погрешость и лосс.\n",
        "\n",
        "Функция **make_dot(yhat)**, получающая на вход тензор, связанный с формулой прогнозирования, сформирует такое изображение графа:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXJlTuHZiewG",
        "colab_type": "code",
        "outputId": "7627d03d-7453-4e3b-8fcf-7653f8d9870c",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "import torchviz\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "torchviz.make_dot(loss) # визуализируем граф вычислений"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f22f3008860>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"342pt\"\n viewBox=\"0.00 0.00 171.50 342.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 338)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-338 167.5,-338 167.5,4 -4,4\"/>\n<!-- 139789421819552 -->\n<g id=\"node1\" class=\"node\">\n<title>139789421819552</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"121,-21 23,-21 23,0 121,0 121,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139789379340216 -->\n<g id=\"node2\" class=\"node\">\n<title>139789379340216</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118.5,-78 25.5,-78 25.5,-57 118.5,-57 118.5,-78\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139789379340216&#45;&gt;139789421819552 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139789379340216&#45;&gt;139789421819552</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-56.7787C72,-49.6134 72,-39.9517 72,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-31.1732 72,-21.1732 68.5001,-31.1732 75.5001,-31.1732\"/>\n</g>\n<!-- 139789379340552 -->\n<g id=\"node3\" class=\"node\">\n<title>139789379340552</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"117,-135 27,-135 27,-114 117,-114 117,-135\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139789379340552&#45;&gt;139789379340216 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139789379340552&#45;&gt;139789379340216</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-113.7787C72,-106.6134 72,-96.9517 72,-88.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-88.1732 72,-78.1732 68.5001,-88.1732 75.5001,-88.1732\"/>\n</g>\n<!-- 139789379341560 -->\n<g id=\"node4\" class=\"node\">\n<title>139789379341560</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-192 26,-192 26,-171 118,-171 118,-192\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139789379341560&#45;&gt;139789379340552 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139789379341560&#45;&gt;139789379340552</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-170.7787C72,-163.6134 72,-153.9517 72,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-145.1732 72,-135.1732 68.5001,-145.1732 75.5001,-145.1732\"/>\n</g>\n<!-- 139789379338872 -->\n<g id=\"node5\" class=\"node\">\n<title>139789379338872</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-263 0,-263 0,-228 54,-228 54,-263\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139789379338872&#45;&gt;139789379341560 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139789379338872&#45;&gt;139789379341560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-227.6724C45.4798,-219.2176 52.5878,-209.1085 58.6352,-200.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-202.4169 64.4601,-192.2234 55.8452,-198.3906 61.5714,-202.4169\"/>\n</g>\n<!-- 139789379339264 -->\n<g id=\"node6\" class=\"node\">\n<title>139789379339264</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-256 72.5,-256 72.5,-235 163.5,-235 163.5,-256\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-242.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139789379339264&#45;&gt;139789379341560 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139789379339264&#45;&gt;139789379341560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-234.9317C103.7191,-225.6309 93.821,-211.8597 85.7479,-200.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-198.3753 79.761,-192.2979 82.7553,-202.4608 88.4395,-198.3753\"/>\n</g>\n<!-- 139789379339600 -->\n<g id=\"node7\" class=\"node\">\n<title>139789379339600</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-334 91,-334 91,-299 145,-299 145,-334\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-306.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139789379339600&#45;&gt;139789379339264 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139789379339600&#45;&gt;139789379339264</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-298.9494C118,-289.058 118,-276.6435 118,-266.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-266.0288 118,-256.0288 114.5001,-266.0289 121.5001,-266.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzxnH0iEEUAM",
        "colab_type": "text"
      },
      "source": [
        "Синие квадратики -- это наши параметры, тензоры, для которых считаются градиенты. Серые квадратики -- это операции Python над этими тензорами или над зависимыми от них значениями.\n",
        "\n",
        "Зелёные квадратики -- то же, что и серые, только в них вычисляются градиенты.\n",
        "\n",
        "Кто знаком с абстрактным синтаксическим деревом, наверняка увидит тут определённое сходство.\n",
        "\n",
        "По названиям квадратов легко определить их смысл -- префиксы определяют вид арифметических операций. Сперва Mul (умножение) выполняет умножение одного параметра: b * x_train_tensor, затем результат складывается (Add) с вторым параметром a, далее из y_train_tensor вычитается (Sub) что получилось, затем возводится в степень (Pow), и наконец вычисление среднего Mean -- это заключительная точка, в которой будут рассчитываться градиенты.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " \n",
        "**Вычисление градиентов в графе происходит снизу вверх!** Зелёный квадрат -- это стартовая точка такого процесса. Не вдаваясь в детали, отметим, что это так называемое **обратное автоматическое дифференцирование** -- мы начинаем с операции, где было получено результирующее значение, и движемся от неё обратно по графу, вычисляя таким образом производные.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU8kqbrEE0ek",
        "colab_type": "text"
      },
      "source": [
        "Почему в одних случаях в квадраты входят две стрелки (как и должно быть с точки зрения двух параметров арифметических операций), а в других всего одна? Какой там второй параметр арифметической операции?\n",
        "\n",
        "Дело в том, что в графе не требуются отдельные квадраты для, например, x или y, потому что мы не считаем градиенты для них. Независимо от количества задействованных тензоров в выражении **в графе учитываются только те параметры, для которых вычисляются градиенты**.\n",
        "\n",
        "Например, попробуйте изменить в команде создания параметра \"a\" его настройку requires_grad на False:\n",
        "\n",
        "`a = torch.randn(1, requires_grad=False, dtype=torch.float, device=device)`\n",
        "\n",
        "Получится граф из шести квадратиков, которые будут линейно связаны друг с другом одиночными стрелками.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcUP191pFnNO",
        "colab_type": "text"
      },
      "source": [
        "##**Задание 1**\n",
        "\n",
        "Выведите графы для error и yhat -- почему получились такие отличия?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTRLgt-C9Rxz",
        "colab_type": "text"
      },
      "source": [
        "## **Ответ на задание 1**\n",
        "Градиент **yhat** вычисляется в зеленом квадратике \"*AddBackward0*\" для этого требуется первый параметр (1) и результат умножения (Sub) с участием второго параметра (1).\n",
        "\n",
        "Градиент  **error** вычисляется в зеленом квадратике \"*SubBackward0*\" для этого требуется результат расчета градиента **yhat** в сером квадратике \"*AddBackward0*\", для которого в свою очередь требуется первый параметр (1) и результат умножения (Sub) с участием второго параметра (1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qu7T5V8ksha",
        "colab_type": "code",
        "outputId": "62a9f024-4fc0-48ed-b9d3-c07deb142372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "torchviz.make_dot(yhat)  # Вывод графа yhat = a + b * x_train_tensor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f22f3008828>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"171pt\"\n viewBox=\"0.00 0.00 171.50 171.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 167)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-167 167.5,-167 167.5,4 -4,4\"/>\n<!-- 139789379341560 -->\n<g id=\"node1\" class=\"node\">\n<title>139789379341560</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"118,-21 26,-21 26,0 118,0 118,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139789379338872 -->\n<g id=\"node2\" class=\"node\">\n<title>139789379338872</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-92 0,-92 0,-57 54,-57 54,-92\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139789379338872&#45;&gt;139789379341560 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139789379338872&#45;&gt;139789379341560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-56.6724C45.4798,-48.2176 52.5878,-38.1085 58.6352,-29.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-31.4169 64.4601,-21.2234 55.8452,-27.3906 61.5714,-31.4169\"/>\n</g>\n<!-- 139789379339264 -->\n<g id=\"node3\" class=\"node\">\n<title>139789379339264</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-85 72.5,-85 72.5,-64 163.5,-64 163.5,-85\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-71.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139789379339264&#45;&gt;139789379341560 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139789379339264&#45;&gt;139789379341560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-63.9317C103.7191,-54.6309 93.821,-40.8597 85.7479,-29.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-27.3753 79.761,-21.2979 82.7553,-31.4608 88.4395,-27.3753\"/>\n</g>\n<!-- 139789379339600 -->\n<g id=\"node4\" class=\"node\">\n<title>139789379339600</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-163 91,-163 91,-128 145,-128 145,-163\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-135.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139789379339600&#45;&gt;139789379339264 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139789379339600&#45;&gt;139789379339264</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-127.9494C118,-118.058 118,-105.6435 118,-95.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-95.0288 118,-85.0288 114.5001,-95.0289 121.5001,-95.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxR21-xXk6Fy",
        "colab_type": "code",
        "outputId": "8956f347-fdaf-4696-f9f9-ca9dad767bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "torchviz.make_dot(error)  # Вывод графа error = y_train_tensor - (a + b * x_train_tensor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f22f3099e48>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"228pt\"\n viewBox=\"0.00 0.00 171.50 228.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 224)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-224 167.5,-224 167.5,4 -4,4\"/>\n<!-- 139789379340552 -->\n<g id=\"node1\" class=\"node\">\n<title>139789379340552</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"117,-21 27,-21 27,0 117,0 117,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139789379341560 -->\n<g id=\"node2\" class=\"node\">\n<title>139789379341560</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-78 26,-78 26,-57 118,-57 118,-78\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139789379341560&#45;&gt;139789379340552 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139789379341560&#45;&gt;139789379340552</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-56.7787C72,-49.6134 72,-39.9517 72,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-31.1732 72,-21.1732 68.5001,-31.1732 75.5001,-31.1732\"/>\n</g>\n<!-- 139789379338872 -->\n<g id=\"node3\" class=\"node\">\n<title>139789379338872</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-149 0,-149 0,-114 54,-114 54,-149\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139789379338872&#45;&gt;139789379341560 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139789379338872&#45;&gt;139789379341560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-113.6724C45.4798,-105.2176 52.5878,-95.1085 58.6352,-86.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-88.4169 64.4601,-78.2234 55.8452,-84.3906 61.5714,-88.4169\"/>\n</g>\n<!-- 139789379339264 -->\n<g id=\"node4\" class=\"node\">\n<title>139789379339264</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-142 72.5,-142 72.5,-121 163.5,-121 163.5,-142\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-128.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139789379339264&#45;&gt;139789379341560 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139789379339264&#45;&gt;139789379341560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-120.9317C103.7191,-111.6309 93.821,-97.8597 85.7479,-86.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-84.3753 79.761,-78.2979 82.7553,-88.4608 88.4395,-84.3753\"/>\n</g>\n<!-- 139789379339600 -->\n<g id=\"node5\" class=\"node\">\n<title>139789379339600</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-220 91,-220 91,-185 145,-185 145,-220\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-192.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139789379339600&#45;&gt;139789379339264 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139789379339600&#45;&gt;139789379339264</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-184.9494C118,-175.058 118,-162.6435 118,-152.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-152.0288 118,-142.0288 114.5001,-152.0289 121.5001,-152.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4o_iqiMF7NY",
        "colab_type": "text"
      },
      "source": [
        "##**Дифференцирование условных конструкций**\n",
        "\n",
        "Самая крутая особенность динамического вычислительного графа в PyTorch в том, что он понимает фактически любые управляющие конструкции Python, код любой сложности. Это по сути означает, что их тоже можно дифференцировать!\n",
        "\n",
        "Следующий код, дополненный условием (оно само по себе не имеет никакого смысла), выведет интересный граф:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Ne289G42UQ",
        "colab_type": "code",
        "outputId": "92ebe05a-4ee6-4355-84ac-b2428fd69870",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "import torchviz\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "# это полная чушь! этот код только для демонстрации разветвления в графе!\n",
        "if loss > 0:\n",
        "  yhat2 = b * x_train_tensor\n",
        "  error2 = y_train_tensor - yhat2\n",
        "  \n",
        "loss += error2.mean()  \n",
        "\n",
        "torchviz.make_dot(loss) # визуализируем граф вычислений"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f22f4857c50>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"284pt\" height=\"399pt\"\n viewBox=\"0.00 0.00 284.00 399.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 395)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-395 280,-395 280,4 -4,4\"/>\n<!-- 139788108004824 -->\n<g id=\"node1\" class=\"node\">\n<title>139788108004824</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"215,-21 123,-21 123,0 215,0 215,-21\"/>\n<text text-anchor=\"middle\" x=\"169\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139788108003816 -->\n<g id=\"node2\" class=\"node\">\n<title>139788108003816</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"180,-78 82,-78 82,-57 180,-57 180,-78\"/>\n<text text-anchor=\"middle\" x=\"131\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139788108003816&#45;&gt;139788108004824 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139788108003816&#45;&gt;139788108004824</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M138.1475,-56.7787C143.2429,-49.1357 150.2317,-38.6524 156.2694,-29.596\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159.2497,-31.4352 161.8845,-21.1732 153.4253,-27.5522 159.2497,-31.4352\"/>\n</g>\n<!-- 139788108002136 -->\n<g id=\"node3\" class=\"node\">\n<title>139788108002136</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"159.5,-135 66.5,-135 66.5,-114 159.5,-114 159.5,-135\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139788108002136&#45;&gt;139788108003816 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139788108002136&#45;&gt;139788108003816</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M116.3857,-113.7787C118.6987,-106.4542 121.8354,-96.5211 124.61,-87.7352\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.9557,-88.763 127.6295,-78.1732 121.2806,-86.655 127.9557,-88.763\"/>\n</g>\n<!-- 139788108001912 -->\n<g id=\"node4\" class=\"node\">\n<title>139788108001912</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"158,-192 68,-192 68,-171 158,-171 158,-192\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139788108001912&#45;&gt;139788108002136 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139788108001912&#45;&gt;139788108002136</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M113,-170.7787C113,-163.6134 113,-153.9517 113,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.5001,-145.1732 113,-135.1732 109.5001,-145.1732 116.5001,-145.1732\"/>\n</g>\n<!-- 139788108001744 -->\n<g id=\"node5\" class=\"node\">\n<title>139788108001744</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"159,-249 67,-249 67,-228 159,-228 159,-249\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139788108001744&#45;&gt;139788108001912 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139788108001744&#45;&gt;139788108001912</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M113,-227.7787C113,-220.6134 113,-210.9517 113,-202.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.5001,-202.1732 113,-192.1732 109.5001,-202.1732 116.5001,-202.1732\"/>\n</g>\n<!-- 139788108003368 -->\n<g id=\"node6\" class=\"node\">\n<title>139788108003368</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-320 0,-320 0,-285 54,-285 54,-320\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139788108003368&#45;&gt;139788108001744 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139788108003368&#45;&gt;139788108001744</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.9558,-284.6724C63.3538,-275.446 78.3987,-264.2498 90.5683,-255.1934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.9097,-257.8138 98.8425,-249.0358 88.7306,-252.1981 92.9097,-257.8138\"/>\n</g>\n<!-- 139788108003144 -->\n<g id=\"node7\" class=\"node\">\n<title>139788108003144</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-313 72.5,-313 72.5,-292 163.5,-292 163.5,-313\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-299.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139788108003144&#45;&gt;139788108001744 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139788108003144&#45;&gt;139788108001744</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M117.1744,-291.9317C116.4837,-283.0913 115.4775,-270.2122 114.6261,-259.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.1119,-258.9949 113.8436,-249.2979 111.1332,-259.5402 118.1119,-258.9949\"/>\n</g>\n<!-- 139788108002192 -->\n<g id=\"node8\" class=\"node\">\n<title>139788108002192</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"199,-391 145,-391 145,-356 199,-356 199,-391\"/>\n<text text-anchor=\"middle\" x=\"172\" y=\"-363.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139788108002192&#45;&gt;139788108003144 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139788108002192&#45;&gt;139788108003144</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M158.6517,-355.9494C150.6484,-345.4266 140.4734,-332.0484 132.3053,-321.3089\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"134.8474,-318.8695 126.0078,-313.0288 129.2757,-323.1071 134.8474,-318.8695\"/>\n</g>\n<!-- 139788108001576 -->\n<g id=\"node11\" class=\"node\">\n<title>139788108001576</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"272.5,-313 181.5,-313 181.5,-292 272.5,-292 272.5,-313\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-299.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139788108002192&#45;&gt;139788108001576 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139788108002192&#45;&gt;139788108001576</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M185.5955,-355.9494C193.8285,-345.3214 204.3179,-331.7806 212.6787,-320.9875\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.4868,-323.0778 218.8439,-313.0288 209.9529,-318.7909 215.4868,-323.0778\"/>\n</g>\n<!-- 139788108005216 -->\n<g id=\"node9\" class=\"node\">\n<title>139788108005216</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"276,-135 178,-135 178,-114 276,-114 276,-135\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139788108005216&#45;&gt;139788108004824 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139788108005216&#45;&gt;139788108004824</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.6475,-113.9795C211.9855,-94.9888 191.4875,-54.6995 179.1119,-30.3751\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"182.1629,-28.6533 174.5088,-21.3276 175.9239,-31.8275 182.1629,-28.6533\"/>\n</g>\n<!-- 139788108002024 -->\n<g id=\"node10\" class=\"node\">\n<title>139788108002024</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"272,-249 182,-249 182,-228 272,-228 272,-249\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139788108002024&#45;&gt;139788108005216 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139788108002024&#45;&gt;139788108005216</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M227,-227.9795C227,-209.242 227,-169.7701 227,-145.3565\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.5001,-145.3276 227,-135.3276 223.5001,-145.3277 230.5001,-145.3276\"/>\n</g>\n<!-- 139788108001576&#45;&gt;139788108002024 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139788108001576&#45;&gt;139788108002024</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M227,-291.9317C227,-283.0913 227,-270.2122 227,-259.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.5001,-259.2979 227,-249.2979 223.5001,-259.2979 230.5001,-259.2979\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV4DeKF9GB3A",
        "colab_type": "text"
      },
      "source": [
        "**Важно**. В графе формируется не линейная последовательность действий, как в коде. \n",
        "\n",
        "**Граф -- это не блок-схема!** В случае блок-схемы алгоритма требовалось бы делать разветвление после первого расчёта loss, а в данном случае видны два независимых вычислительных блока, которые разветвляются не по условию if loss > 0 , а по вхождению параметров (в данном случае параметра b) в различные цепочки вычислений. Эти блоки/цепочки в процессе вычисления градиентов комбинируются автоматически.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fR3Zp9aHz5m",
        "colab_type": "text"
      },
      "source": [
        "##**Оптимизатор**\n",
        "\n",
        "Несмотря на автоматическое вычисление градиентов, сейчас мы, как и в случае с NumPy, параметры обновляем вручную, явными командами в коде. Сейчас их всего два, но что если их будут сотни или тысячи, как в крупных и сложных моделях? На помощь приходят оптимизаторы. **Пакет torch.optim -- это второй из трёх ключевых пакетов PyTorch**.\n",
        "\n",
        "\n",
        "\n",
        "Оптимизатор получает на вход список параметров, скорость обучения и возможно ещё ряд других настроечных коэффициентов, и выполняет их автоматическое обновление с помощью метода **step().** Не требуется в таком случае и ручного обнуления градиентов -- для этого есть метод **zero_grad()**.\n",
        "\n",
        "\n",
        "Различные алгоритмы оптимизации и реализованы в данном пакете torch.optim.  Один из популярных алгоритмов -- это **стохастический градиентный спуск** (Stochastic Gradient Descent, SGD). Как он работает внутри, на данном шаге неважно, достаточно знать, что он умеет реализовывать пакетный спуск -- используя в обновлении сразу всю обучающую выборку.\n",
        "\n",
        "https://pytorch.org/docs/stable/optim.html?source=post_page---------------------------#torch.optim.SGD\n",
        "\n",
        "Всё, что потребуется изменить в исходном коде -- это создать сам оптимизатор, связав его с параметрами, и соответственно, сменить ручное обновление параметров a и b и обнуление их градиентов на вызов методов оптимизатора step() и zero_grad().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mohMh0ECmw1K",
        "colab_type": "code",
        "outputId": "557c5625-10aa-4137-a7ec-ac893478d507",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print('Параметры в начале обучения: ', a, b)\n",
        "\n",
        "# скорость обучения\n",
        "lr = 0.1\n",
        "\n",
        "# количество эпох\n",
        "n_epochs = 1000 \n",
        "\n",
        "# создаём SGD оптимизатор для автоматического обновления параметров \n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "    loss.backward()\n",
        "    \n",
        "    # with torch.no_grad():\n",
        "    #    a -= lr * a.grad\n",
        "    #    b -= lr * b.grad\n",
        "    optimizer.step()  \n",
        "    \n",
        "    # a.grad.zero_()\n",
        "    # b.grad.zero_()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print('Параметры после обучения:  ', a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Параметры в начале обучения:  tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "Параметры после обучения:   tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7RIFwl0ISpm",
        "colab_type": "text"
      },
      "source": [
        "Параметры в начале и после обучения:\n",
        "\n",
        "\n",
        "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
        "\n",
        "\n",
        "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n",
        "\n",
        "По сути, мы таким образом оптимизировали процесс оптимизации!\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhSl1VXCIiQc",
        "colab_type": "text"
      },
      "source": [
        "##**Лосс**\n",
        "\n",
        "Сейчас и лосс мы пока считаем вручную, явно записывая формулу расчёта \n",
        "loss = (error ** 2).mean(). На помощь приходит **третий (из трёх) ключевой пакет PyTorch -- torch.nn**, добавляющий уровень абстракции для довольно низкоуровневых возможностей autograd.\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html?highlight=nn#module-torch.nn\n",
        "\n",
        "В нём, в частности, содержится набор стандартных функций для расчёта всевозможных видов ошибок/погрешностей.\n",
        "\n",
        "В нашем случае, функция расчёта среднеквадратичной ошибки называется **MSELoss**. Сама по себе это не функция, которая вызывается напрямую, а скорее \"фабрика\" функций, которая создаёт нужную нам функцию, причём можно этой фабрике задавать параметры желаемой функций, методы агрегации данных (например, reduction=\"mean\" означает вычисление среднего, reduction=\"sum\" означает вычисление суммы). На вход подобным функциям подаётся обучающая выборка и тензор с параметрами, для которых рассчитываются градиенты.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93krP0x3uCY8",
        "colab_type": "code",
        "outputId": "9aec19a7-62ad-418e-a326-d575bac1ee7f",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from torch import optim, nn\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "# скорость обучения\n",
        "lr = 0.1\n",
        "\n",
        "# количество эпох\n",
        "n_epochs = 1000 \n",
        "\n",
        "# функция расчёта лосса\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# создаём SGD оптимизатор для автоматического обновления параметров \n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    \n",
        "    # error = y_train_tensor - yhat\n",
        "    # loss = (error ** 2).mean()\n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()  \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1znvwTI7lw",
        "colab_type": "text"
      },
      "source": [
        "Обратите внимание, что мы уже избавились фактически от всего ручного кодирования, связанного с градиентами и другими оптимизационными расчётами!\n",
        "\n",
        "**Получился по сути шаблон, в котором осталась только явно одна задаваемая вручную строка, где вычисляется yhat -- она определяет нашу формулу прогноза, и её можно менять на любые другие нужные нам для анализа зависимости.**\n",
        "\n",
        "Соответственно, напрашивается вопрос, а можно ли как-то абстрагировать и этот момент, чтобы не искать в оптимизационном коде нужную строчку, да и в целом перейти на более удобный формат представления изучаемых зависимостей? Такая форма абстракции в PyTorch -- это модель.\n",
        "\n",
        "Созданию моделей PyTorch посвящено следующее занятие."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W1syOJ0Oo9a",
        "colab_type": "text"
      },
      "source": [
        "##**Задание 2**\n",
        "\n",
        "Измените в данном шаблоне прогноз на основе линейной регрессии на более сложную зависимость. С функциями прогноза какой сложности сможет уверенно справиться наш простой базовый шаблон PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lIimTjvmitx",
        "colab_type": "text"
      },
      "source": [
        "Повторение:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3MpAp4UTGEk",
        "colab_type": "code",
        "outputId": "ac786855-f6cd-4ffc-d1ee-3d6557e31abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "\n",
        "'''Настройка дефайса'''\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "'''Инициализация повторяемой последовательности рандомных чисел'''\n",
        "np.random.seed(42)  \n",
        "\n",
        "\n",
        "'''Создание массива из 100 случайных ноликов/единичек'''\n",
        "sz = 100\n",
        "x = np.random.rand(sz, 1)\n",
        "\n",
        "'''Построение функции'''\n",
        "#y = 3/4 * x * np.random.randn(sz, 1)\n",
        "y = 7 * x**2 + 3 + 0.1 * np.random.randn(sz, 1)\n",
        "\n",
        "'''Формирование и перетасовка индексов от 0 до 99'''\n",
        "idx = np.arange(sz)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "'''Обучение первыми 80-ми индексами, валидация 20-ю'''\n",
        "sz80 = int(sz*0.8)\n",
        "train_idx = idx[: sz80]\n",
        "val_idx = idx[sz80:]\n",
        "\n",
        "'''Наборы обучающих данных и наборы для валидации'''\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]\n",
        "\n",
        "'''Визуализация '''\n",
        "plt.scatter(x_train, y_train)\n",
        "plt.title('Обучающая_выборка')\n",
        "plt.show()\n",
        "plt.scatter(x_val, y_val, color = 'red')\n",
        "plt.title('Проверочная_выборка')\n",
        "plt.show()\n",
        "\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "lr = 0.1  # скорость обучения\n",
        "n_epochs = 1000  # количество эпох\n",
        "loss_fn = nn.MSELoss(reduction='mean')  # функция расчета лосса\n",
        "\n",
        "optimizer = optim.SGD([a, b], lr=lr)  # оптимизатор для авто обносления\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a * x_train_tensor**2 + b\n",
        "    \n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "print(a, b)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxl9apDAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSR1jcEtSxxjcktQx/x+PmnEakk8dhQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "tensor([6.9803], requires_grad=True) tensor([3.0151], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d3WkxEVV1F-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "https://vk.com/lambda_brain"
      ]
    }
  ]
}
