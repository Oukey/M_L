{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myHW_5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oukey/M_L/blob/master/myHW_5_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpATm-3nMumX",
        "colab_type": "text"
      },
      "source": [
        "Импортируем нужные модули:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulQBMYaL-9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "# import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "# import numpy as np\n",
        "# from torch.nn import Linear, Sigmoid\n",
        "from torch import optim, nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RZM2J1hNOso",
        "colab_type": "text"
      },
      "source": [
        "Задание гипер-параметров:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaNbzKaANSfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 28*28      # Размер изображения в точках\n",
        "hidden_size = 700       # Количество нейронов в скрытом слое\n",
        "num_classes = 10        # Количество распознающихся классов (10 цифр)\n",
        "n_epochs = 5            # Количество эпох\n",
        "batch_size = 10         # Размер мини-пакета входных данных\n",
        "lr = 0.001              # Скорость обучения"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA2eK1YjO7bA",
        "colab_type": "text"
      },
      "source": [
        "Загрузка и проверка размеров датасетов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izXtBPi_PN_F",
        "colab_type": "code",
        "outputId": "36966957-e6ab-4b1e-9d8e-154a1d6e116c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "mnist_trainset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_testset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "'''\n",
        "root - каталог размещения датасета\n",
        "download - необходимость скачивания датасета\n",
        "train - обучающий(True) или тестовый(False)\n",
        "transform - трансформация, предваритеьная обработка\n",
        "'''\n",
        "print(len(mnist_trainset))  # вывод размера обучающего датасета\n",
        "print(len(mnist_testset))  # вывод размера тестового датасета"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFeUBp28QawG",
        "colab_type": "text"
      },
      "source": [
        "Обработка датасета мини-пакетами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouoaB0GdQieF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Загрузчик обучающих данных\n",
        "train_loader = torch.utils.data.DataLoader(dataset=mnist_trainset, batch_size=batch_size, shuffle=True)\n",
        "# Загрузчик тестовых данных\n",
        "test_loader = torch.utils.data.DataLoader(dataset=mnist_testset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUxoVC8-R3yF",
        "colab_type": "text"
      },
      "source": [
        "Функция стандартного шага обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8NbuZLPSby9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Инициализация девайса\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def make_train_step(model, loss_fn, otpimizer):\n",
        "    def train_step(x, y):\n",
        "        model.train()\n",
        "        yhat = model(x)\n",
        "        loss = loss_fn(yhat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        return loss.item()\n",
        "    return train_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI6CV1H0UnDh",
        "colab_type": "text"
      },
      "source": [
        "Задание модели, вида оптимизации. Обучение и расчет лосса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMZg1UrDUwps",
        "colab_type": "code",
        "outputId": "7800d9f4-b0c1-4c38-e43b-1f0629729c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(700, 700),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, num_classes))\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adamax(model.parameters(), lr=lr)\n",
        "\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        # преобразование в одномерный вектор\n",
        "        images = images.reshape(-1, 28*28).to(device)  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        loss = train_step(images, labels)\n",
        "    print(epoch)\n",
        "\n",
        "print('model', model.state_dict())\n",
        "print('loss', loss)        "
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "model OrderedDict([('0.weight', tensor([[-0.0123, -0.0256,  0.0174,  ...,  0.0280, -0.0255, -0.0296],\n",
            "        [ 0.0125,  0.0065,  0.0100,  ...,  0.0343, -0.0233, -0.0121],\n",
            "        [ 0.0219,  0.0081, -0.0201,  ...,  0.0031,  0.0275,  0.0154],\n",
            "        ...,\n",
            "        [-0.0296, -0.0275, -0.0047,  ...,  0.0159,  0.0137,  0.0164],\n",
            "        [ 0.0099,  0.0271,  0.0308,  ...,  0.0292,  0.0181,  0.0204],\n",
            "        [ 0.0168, -0.0031, -0.0036,  ...,  0.0052, -0.0160,  0.0011]])), ('0.bias', tensor([ 2.7806e-03,  3.2412e-02,  1.7372e-02, -3.5917e-02,  2.4504e-02,\n",
            "         3.2653e-03,  4.4906e-02, -2.7591e-02,  1.1626e-02, -1.1298e-02,\n",
            "        -1.5462e-02, -5.7980e-03, -8.0783e-03,  2.2288e-02, -1.3054e-02,\n",
            "         1.0545e-02, -5.0332e-02, -1.0981e-03,  5.1418e-03, -4.2777e-02,\n",
            "         4.8796e-03, -1.7873e-02, -4.0158e-02,  3.5151e-03, -2.1170e-02,\n",
            "         1.6871e-02, -5.2871e-03, -2.4208e-02, -1.5646e-02,  7.9622e-03,\n",
            "         7.5051e-03, -3.7682e-02, -9.0879e-03,  4.7180e-02,  1.3719e-02,\n",
            "        -6.9815e-02, -1.3425e-02, -1.5773e-03,  2.3499e-02,  2.5876e-03,\n",
            "        -2.7260e-03,  2.5321e-03, -1.6188e-02,  2.8371e-02, -2.4514e-02,\n",
            "        -1.8315e-02,  9.6950e-03, -2.0810e-02,  1.3175e-02, -7.2183e-02,\n",
            "         4.9881e-03,  8.2359e-03,  1.8078e-02, -1.8943e-02, -5.0715e-02,\n",
            "         2.8208e-04,  1.0324e-02,  1.2339e-02,  9.4582e-03,  3.3350e-02,\n",
            "         1.6469e-02, -1.6310e-02, -4.1213e-02, -4.1326e-04,  2.9304e-02,\n",
            "         2.2486e-02, -3.1661e-02,  4.7625e-03, -6.2554e-03,  4.7526e-03,\n",
            "        -7.5951e-03, -5.1207e-03,  2.9593e-02, -7.3675e-03, -1.0770e-02,\n",
            "         3.4523e-02, -6.5948e-02,  2.2191e-02,  3.4884e-02, -1.2718e-02,\n",
            "        -1.6845e-02, -1.6109e-03,  3.8977e-02, -1.7565e-02,  2.2439e-02,\n",
            "        -6.8996e-03,  3.3623e-02, -1.4119e-02, -2.0389e-02, -3.6586e-03,\n",
            "         1.9773e-02, -5.7389e-02, -1.7579e-02, -1.3541e-02,  3.7400e-02,\n",
            "        -1.8154e-02, -5.0999e-03, -1.2378e-03, -7.7943e-03, -2.6122e-02,\n",
            "         3.6879e-03,  2.4470e-03,  1.2713e-02,  1.1516e-02, -3.8137e-02,\n",
            "         2.3927e-02,  2.9849e-02,  1.5796e-02, -2.0917e-02, -1.8791e-02,\n",
            "         5.2519e-02, -1.1987e-02,  3.1868e-02,  3.9172e-02,  1.3892e-02,\n",
            "        -2.6591e-02, -1.1530e-02, -2.4780e-02,  3.8430e-02,  3.4069e-02,\n",
            "         2.5943e-02,  5.2395e-02, -5.6987e-03,  1.5726e-02,  3.3389e-02,\n",
            "         1.8587e-02,  2.5005e-02,  2.4324e-02,  8.6814e-03,  7.8479e-04,\n",
            "        -2.4880e-02, -5.7622e-02, -7.5517e-02, -3.6173e-03,  1.1038e-02,\n",
            "         3.4865e-03, -3.9096e-02,  4.6585e-02, -4.9199e-03, -1.0150e-02,\n",
            "         2.6405e-02,  3.6689e-02,  3.2759e-02, -3.1348e-02, -2.2890e-02,\n",
            "        -5.0304e-03, -1.9337e-03, -4.8069e-02, -5.7493e-02, -9.6360e-03,\n",
            "         1.5927e-02, -1.6154e-02,  3.2558e-03, -3.3439e-03, -5.0319e-02,\n",
            "         2.0925e-02, -1.2877e-02, -3.7825e-03,  1.4161e-02, -2.2717e-02,\n",
            "        -4.8098e-02,  2.3878e-02, -3.4791e-02,  1.5012e-02, -2.1832e-02,\n",
            "         1.9899e-02,  2.5877e-02, -2.2606e-02, -9.4593e-03,  2.6509e-03,\n",
            "         3.8484e-02,  1.9105e-02,  2.0550e-02, -8.3221e-03,  4.8188e-04,\n",
            "         1.7864e-02, -4.4097e-03, -1.4175e-02, -5.5251e-02,  3.4391e-02,\n",
            "        -2.1958e-02,  3.5823e-02, -3.7554e-02,  9.9857e-03, -1.1440e-03,\n",
            "         3.2834e-02, -3.3827e-02,  2.8214e-03, -2.6539e-02, -3.0848e-02,\n",
            "        -4.6279e-02,  2.1965e-03, -2.1990e-02, -3.9033e-02, -3.5445e-02,\n",
            "        -5.6746e-03,  3.9299e-02,  4.2970e-02,  3.6492e-03, -2.4487e-02,\n",
            "         2.8863e-02, -1.9899e-02,  1.6538e-02, -1.2805e-02, -4.7501e-03,\n",
            "         3.1630e-03,  2.7269e-02, -1.9333e-02, -3.4831e-02,  2.4614e-02,\n",
            "        -1.4098e-02,  2.0908e-02, -5.3785e-03,  7.4071e-02, -1.5757e-02,\n",
            "         1.8863e-02,  3.3057e-02,  2.4970e-03,  1.2463e-02,  1.0787e-02,\n",
            "        -9.9988e-03, -1.5133e-02, -8.3619e-03,  3.6393e-02,  4.0862e-02,\n",
            "        -6.7518e-03,  5.7438e-02, -3.1454e-03,  4.2251e-02,  2.9016e-02,\n",
            "        -1.4189e-02,  3.6958e-03,  3.3818e-02,  3.5245e-02, -1.9276e-02,\n",
            "         7.0406e-03,  3.4634e-02, -3.3198e-02, -2.9018e-02, -2.9670e-02,\n",
            "         8.6135e-03, -4.5564e-02,  2.7135e-02,  3.6027e-02,  1.7427e-02,\n",
            "        -1.4818e-02,  1.1753e-02, -2.2270e-04,  1.5985e-02, -6.8736e-03,\n",
            "         1.0162e-02,  8.0806e-03, -2.9130e-02,  5.1718e-03, -2.5840e-02,\n",
            "        -3.8647e-02, -6.2893e-02,  5.1887e-02,  3.6761e-02,  1.9327e-02,\n",
            "         3.9106e-02,  9.2313e-03,  5.8808e-03, -2.2209e-02,  1.7884e-02,\n",
            "        -1.3214e-02,  5.9547e-03,  4.5926e-02, -3.6437e-02,  4.8232e-02,\n",
            "        -3.2920e-02, -1.1601e-03,  5.0316e-03, -1.3606e-02,  2.2321e-02,\n",
            "        -4.3048e-02, -4.9669e-02, -6.0465e-02,  1.3527e-02,  5.0092e-02,\n",
            "        -4.1568e-02,  2.0325e-02,  6.1924e-03, -1.4849e-02,  3.0092e-02,\n",
            "         2.4029e-02,  1.4494e-02, -8.3859e-03,  3.5800e-02,  4.0585e-02,\n",
            "         3.2972e-03,  6.5500e-03, -1.3945e-02, -4.2934e-03,  2.9040e-02,\n",
            "        -2.8914e-02, -4.2676e-02, -1.7526e-02, -1.1943e-02, -2.6782e-02,\n",
            "        -3.2834e-02, -4.1656e-02, -4.9981e-02,  5.3397e-02,  3.6374e-02,\n",
            "         2.3369e-02, -8.2049e-03,  2.1949e-02, -6.0322e-03, -3.8539e-02,\n",
            "         3.2442e-02, -1.3478e-02,  2.2692e-02, -2.2313e-02,  8.6477e-03,\n",
            "        -2.9823e-02, -3.7189e-02,  2.5976e-02,  3.3141e-02,  4.0722e-02,\n",
            "        -1.7915e-02, -7.1733e-02, -1.5404e-03,  1.9312e-02,  1.4860e-02,\n",
            "        -3.4675e-02,  3.7927e-02, -2.6417e-02,  1.0758e-02,  3.3479e-02,\n",
            "         1.7282e-02, -5.3296e-03, -9.8970e-03, -9.5799e-03,  4.1043e-02,\n",
            "        -3.7874e-02, -1.5578e-02, -8.0656e-04, -1.2159e-02,  6.0506e-02,\n",
            "         3.1952e-02,  1.6867e-02,  5.0540e-04, -1.5933e-02,  1.9289e-02,\n",
            "        -6.9467e-04, -1.9067e-02,  4.5317e-02, -1.6218e-04, -1.0033e-03,\n",
            "         1.7144e-02, -6.5919e-03, -3.1545e-02,  1.1112e-03,  3.4268e-02,\n",
            "        -1.5571e-02,  4.0007e-03, -4.7125e-02,  2.1139e-03, -1.9449e-02,\n",
            "        -3.1127e-02,  4.1742e-02, -1.1851e-02,  2.0054e-05, -9.4209e-03,\n",
            "         3.2190e-02, -3.9712e-02,  5.3184e-03,  4.1682e-02,  5.3305e-03,\n",
            "        -3.8594e-03,  7.7592e-02, -6.5016e-03,  3.0956e-03, -2.0004e-02,\n",
            "        -8.7513e-03, -1.0320e-02,  2.5155e-02,  2.3697e-02, -3.2427e-02,\n",
            "         7.8325e-03, -2.8540e-02,  5.8414e-03,  4.5103e-03,  7.6676e-02,\n",
            "         4.2425e-02, -2.0587e-02, -2.1097e-03,  2.0739e-02, -7.5670e-03,\n",
            "        -1.2115e-02,  2.4108e-03, -1.8682e-02,  2.2046e-02,  2.1578e-03,\n",
            "         2.9908e-02,  4.5157e-02,  6.8691e-02,  1.8716e-04, -2.8193e-02,\n",
            "         1.2078e-03, -4.2818e-02, -5.1823e-02, -1.5647e-03, -2.8235e-02,\n",
            "        -1.5698e-04,  1.0150e-02, -3.0767e-03,  3.0312e-02,  2.2451e-02,\n",
            "         9.1019e-03, -9.3002e-03, -2.4414e-02,  7.3521e-03, -2.4127e-02,\n",
            "         8.3602e-03,  3.2921e-02, -4.2968e-02,  2.9091e-02, -3.0312e-02,\n",
            "         1.1810e-02, -5.2494e-02,  4.8868e-02, -1.8289e-02,  1.5473e-02,\n",
            "        -1.3361e-02, -1.0752e-02, -5.9463e-02, -1.3914e-05,  2.5640e-02,\n",
            "        -4.8709e-02,  5.4971e-02, -4.2518e-03, -2.0613e-02, -2.8439e-02,\n",
            "        -7.4809e-04,  1.0808e-02,  6.7564e-02,  2.9403e-02, -5.0798e-02,\n",
            "        -2.1072e-02,  3.6010e-02, -1.5263e-02, -2.0312e-02,  2.7092e-03,\n",
            "        -2.2856e-02, -3.4325e-02, -7.6218e-03, -4.6710e-02,  6.3625e-03,\n",
            "         3.7077e-02,  5.5886e-03, -5.0069e-02,  1.0485e-02,  3.5139e-02,\n",
            "         3.6826e-02, -5.5042e-02, -1.6044e-02, -1.0779e-02,  2.3902e-02,\n",
            "         2.8650e-02,  1.9020e-02, -8.4611e-03, -4.1428e-02, -4.0611e-03,\n",
            "        -3.9468e-03,  5.7471e-03,  1.6239e-03,  3.4257e-03, -8.9723e-03,\n",
            "         2.0739e-02,  3.6660e-02,  2.4053e-02,  1.8105e-02,  2.1194e-02,\n",
            "        -1.6738e-02, -5.3260e-03, -1.1453e-02,  1.4391e-02, -1.4131e-03,\n",
            "         3.1668e-02,  3.3553e-02,  2.2783e-02, -7.0482e-03, -7.1571e-03,\n",
            "         2.1123e-02,  3.3017e-02, -4.6775e-03, -6.3726e-02, -9.0515e-03,\n",
            "         1.7772e-02, -2.8924e-02,  5.1200e-03, -3.0450e-02,  7.9261e-02,\n",
            "         2.0901e-02, -1.8794e-02, -2.9587e-02,  2.1246e-02, -3.8970e-02,\n",
            "        -1.4623e-02,  2.4510e-02,  1.5987e-02, -1.4635e-02,  3.3269e-02,\n",
            "        -1.2364e-02, -1.0563e-03, -1.3345e-02,  5.1502e-02,  3.4217e-03,\n",
            "        -9.6256e-03, -4.4392e-02, -8.5579e-03,  4.7882e-02, -1.4888e-02,\n",
            "        -9.1953e-03,  2.2477e-03, -3.1957e-02, -3.1421e-03,  8.9096e-03,\n",
            "         3.9180e-02,  4.1310e-02, -4.3746e-03, -4.0790e-02, -3.2249e-02,\n",
            "        -7.1375e-02, -1.4340e-02,  1.4628e-02,  5.0502e-02, -3.1175e-03,\n",
            "        -3.8705e-02, -1.2218e-02, -1.3033e-02, -2.0778e-02, -5.9215e-03,\n",
            "         2.7285e-02,  2.9373e-02, -3.1617e-02, -2.4501e-02, -4.9997e-03,\n",
            "        -7.4462e-03,  1.7766e-02,  3.3809e-02,  3.4393e-02, -1.0478e-02,\n",
            "         1.7190e-02, -3.3243e-02, -8.7263e-03, -2.9392e-03,  1.4829e-02,\n",
            "        -4.2404e-02, -3.7219e-02,  1.5115e-02, -4.6273e-04, -3.1646e-02,\n",
            "        -5.8321e-03, -1.3134e-02, -2.2775e-02,  3.5245e-02,  1.8284e-02,\n",
            "        -4.0438e-02, -4.0001e-02, -1.6732e-02, -9.7703e-03,  1.8638e-02,\n",
            "         9.7703e-03, -4.8639e-02,  2.8654e-02, -1.0014e-02, -3.9986e-02,\n",
            "        -2.7772e-02,  3.5064e-02, -1.1831e-02,  4.9159e-02, -3.7831e-02,\n",
            "        -4.0140e-02, -2.2547e-02, -3.2215e-03, -4.0723e-02,  4.5620e-02,\n",
            "        -2.0725e-03,  2.8714e-03, -2.8257e-02,  6.9271e-04, -1.5773e-02,\n",
            "         3.6106e-02,  4.2300e-02, -2.3685e-02,  2.3496e-02,  7.2339e-03,\n",
            "        -9.1833e-03, -3.7263e-03, -2.5802e-02, -2.6454e-02,  4.7136e-03,\n",
            "        -2.7448e-02, -4.6514e-02, -8.6227e-03,  5.2504e-02, -1.9965e-02,\n",
            "        -3.0590e-02,  3.9049e-02,  3.2359e-02, -3.2433e-02,  6.6410e-02,\n",
            "        -2.5823e-02, -8.5056e-03, -3.0415e-02,  1.2930e-02,  9.6344e-03,\n",
            "        -1.7442e-02, -4.9212e-02, -2.3517e-03,  7.1891e-02, -3.0099e-02,\n",
            "        -2.6073e-03, -3.0401e-04, -1.9135e-02,  1.6681e-03,  2.4224e-02,\n",
            "        -4.1606e-02,  7.9454e-03, -5.6096e-02,  1.7239e-02,  3.0790e-02,\n",
            "        -4.6271e-02, -6.5425e-03, -8.3008e-03,  1.9515e-02,  1.1322e-02,\n",
            "        -5.0327e-02, -4.3342e-02,  3.2490e-02,  3.7294e-02,  1.0215e-02,\n",
            "        -1.0927e-02,  1.8583e-02,  2.5745e-02,  1.2641e-02, -3.3271e-02,\n",
            "         1.2854e-02, -8.0631e-03,  4.5322e-02,  4.7678e-02,  1.9920e-03,\n",
            "         5.6965e-03, -2.0222e-02, -1.4235e-02, -4.0840e-02, -1.6290e-02,\n",
            "        -1.9158e-02,  4.6094e-03, -2.2689e-02, -6.1613e-03,  4.4609e-02,\n",
            "        -2.1338e-02,  1.7258e-02, -2.8624e-02, -2.3634e-02,  3.2636e-02,\n",
            "        -3.0908e-02,  1.2787e-02,  3.2745e-02,  4.0991e-02, -1.6790e-02,\n",
            "        -2.5923e-02,  6.3096e-03, -3.2367e-02,  4.0943e-04, -4.6757e-02,\n",
            "        -1.9794e-02,  1.3218e-02,  3.3074e-02,  2.4566e-02,  4.1926e-02,\n",
            "        -2.8941e-02, -3.4244e-02,  6.0645e-02, -3.1196e-02,  4.1852e-02,\n",
            "         2.2076e-03, -4.1002e-02,  1.0769e-03, -4.0564e-02, -1.1926e-02,\n",
            "         4.3221e-02, -2.8771e-02,  2.4011e-02,  4.8631e-02, -8.0115e-03,\n",
            "        -3.0743e-02,  5.5242e-03,  2.4955e-03,  2.6002e-02,  1.6183e-02,\n",
            "         1.3395e-02,  5.5537e-02,  3.7349e-02,  2.5440e-02, -1.0243e-02])), ('2.weight', tensor([[-0.0279,  0.0161,  0.0019,  ...,  0.0342,  0.0396, -0.0014],\n",
            "        [ 0.0045, -0.0112,  0.0391,  ...,  0.0452, -0.0509,  0.0547],\n",
            "        [ 0.0173, -0.0529,  0.0342,  ...,  0.0121,  0.0154, -0.0104],\n",
            "        ...,\n",
            "        [-0.0076, -0.0293, -0.0439,  ...,  0.0178,  0.0005,  0.0217],\n",
            "        [ 0.0738,  0.0084,  0.0795,  ...,  0.0335,  0.1121, -0.0095],\n",
            "        [-0.1300,  0.0162,  0.0741,  ..., -0.0512, -0.0293, -0.0671]])), ('2.bias', tensor([-2.8941e-02,  3.1119e-02, -1.5025e-03,  1.6046e-02, -3.2142e-02,\n",
            "        -4.8871e-02,  3.1533e-02, -1.2599e-02,  5.2337e-02,  8.9540e-04,\n",
            "         3.5018e-02,  3.0332e-02, -2.3281e-03,  5.2174e-02,  1.9616e-02,\n",
            "        -1.2808e-02,  7.6924e-03, -4.8859e-02,  4.7134e-02,  9.6017e-02,\n",
            "        -2.1649e-03, -3.2466e-03,  3.8787e-03,  8.5283e-02,  5.9968e-02,\n",
            "        -3.9668e-02,  7.3157e-02, -1.3229e-02,  3.3758e-03, -3.0249e-02,\n",
            "        -2.9985e-02, -8.8451e-03, -2.0246e-02,  1.6331e-02,  1.3490e-02,\n",
            "         5.2622e-03,  5.6734e-02,  4.3774e-02,  3.5534e-02,  3.7960e-02,\n",
            "         1.3780e-02, -3.1001e-02, -3.5256e-02,  2.6870e-03, -1.6018e-02,\n",
            "        -1.5838e-02, -1.4104e-03,  1.5550e-02,  4.5453e-02,  8.8520e-03,\n",
            "         2.8775e-03,  9.1345e-03,  1.6858e-02, -3.2646e-02, -1.8218e-02,\n",
            "         9.6506e-03,  7.7126e-02, -1.5725e-02, -5.7041e-02,  2.9588e-02,\n",
            "         8.1141e-03,  1.7746e-02,  6.9951e-02,  1.7598e-02, -7.1322e-03,\n",
            "         2.3331e-03, -1.3982e-02,  4.3112e-02,  2.1584e-02,  1.8210e-03,\n",
            "         7.2792e-02,  6.0128e-02,  8.4931e-02,  2.7644e-02,  4.6559e-02,\n",
            "         3.3707e-02, -3.2436e-02, -8.5074e-03, -1.3099e-02,  5.2406e-02,\n",
            "         6.7887e-02,  2.8933e-02, -4.8616e-02, -1.5855e-02, -2.7595e-02,\n",
            "        -3.1060e-02, -1.8797e-02,  5.2883e-03, -3.0831e-02,  6.6811e-02,\n",
            "        -2.8375e-03,  4.4140e-02, -5.1426e-02,  6.6432e-02,  8.7154e-03,\n",
            "         3.7875e-02,  3.9303e-02,  4.2515e-02,  2.5004e-04, -2.2877e-02,\n",
            "         6.5496e-02,  3.4534e-02,  9.6762e-03,  6.7362e-02,  2.3072e-02,\n",
            "        -1.5975e-02, -3.3483e-02,  1.4340e-02,  6.9315e-02, -5.3956e-03,\n",
            "        -2.0416e-02,  3.2657e-02,  2.2922e-02,  2.4802e-02, -2.8707e-02,\n",
            "        -4.2861e-03,  1.5983e-02, -8.4987e-03,  5.1158e-02,  2.9455e-02,\n",
            "         5.2018e-02, -2.9396e-02,  2.6121e-03,  6.6909e-02,  2.8699e-02,\n",
            "        -1.1495e-02, -5.6375e-03, -3.4514e-02, -3.0659e-02,  4.3496e-02,\n",
            "         9.0405e-03, -3.7565e-02,  9.7714e-02, -1.9898e-02,  4.4048e-02,\n",
            "         2.9972e-02,  5.6309e-03,  9.5589e-03, -3.1851e-02,  1.5837e-02,\n",
            "        -2.5790e-02,  2.6814e-05,  9.2954e-02,  1.0947e-02, -1.2964e-02,\n",
            "        -5.3833e-02, -2.4619e-02,  2.7257e-04,  8.5691e-03,  5.3797e-02,\n",
            "        -4.1813e-02,  4.8781e-03,  5.5755e-03,  4.0269e-02, -3.2624e-03,\n",
            "         4.1734e-05, -3.3612e-03,  5.1627e-02, -3.6942e-02,  1.3251e-02,\n",
            "        -4.1205e-02,  6.0916e-02, -2.6956e-03,  9.4496e-03,  5.5198e-02,\n",
            "         5.3690e-02,  3.8982e-02, -1.0389e-03, -5.3801e-02,  7.9831e-03,\n",
            "         1.1573e-02,  1.5316e-02,  4.0220e-02, -5.8429e-03, -1.9455e-02,\n",
            "         2.8043e-02,  1.8300e-02,  1.5802e-02,  6.1729e-02,  9.9102e-03,\n",
            "         2.1853e-02, -5.1986e-02, -4.7543e-02,  6.0330e-03,  2.9925e-03,\n",
            "         5.1055e-02,  3.1138e-02,  4.3328e-02,  1.7409e-02,  2.1745e-02,\n",
            "         3.5245e-02, -1.7246e-02, -5.1044e-03,  6.6358e-02, -2.0402e-02,\n",
            "         2.1051e-02,  2.5119e-02, -8.3159e-03,  2.0169e-02, -4.3491e-02,\n",
            "         2.1680e-02,  3.5421e-02,  1.9065e-02,  1.8569e-02, -2.3254e-02,\n",
            "         3.0999e-02, -1.7258e-02,  7.3131e-03,  3.6356e-03, -2.2313e-02,\n",
            "         1.9605e-02,  6.0179e-02,  4.1505e-02, -9.6032e-03,  3.0043e-02,\n",
            "         5.9085e-02, -3.9451e-02, -3.5082e-02, -9.0638e-03,  2.9193e-02,\n",
            "         9.4062e-03,  3.0878e-02, -2.0183e-02,  3.0577e-02, -3.7136e-02,\n",
            "         1.1765e-02, -3.4614e-03, -6.8829e-02,  1.2568e-03, -4.9142e-03,\n",
            "        -2.0243e-02,  3.1126e-04, -3.1816e-03, -1.7193e-02,  2.9978e-02,\n",
            "         4.0081e-03, -3.0165e-02,  2.5457e-02,  3.6540e-02, -9.5070e-03,\n",
            "         4.2631e-02,  4.7006e-03,  3.2949e-02, -4.4198e-03, -3.4864e-02,\n",
            "        -6.1135e-03,  2.5861e-02, -5.1738e-02, -2.6774e-02, -2.3037e-02,\n",
            "        -1.5782e-02, -1.3866e-02,  7.5370e-03,  8.1538e-03, -2.0983e-02,\n",
            "         1.2131e-02,  3.0903e-02, -3.7148e-02,  1.1353e-02,  4.3982e-02,\n",
            "        -1.2367e-02, -2.4715e-02, -1.2428e-02, -4.0116e-02,  2.9439e-02,\n",
            "        -4.2364e-03,  1.9320e-02,  5.8497e-02, -1.3811e-02, -5.7134e-03,\n",
            "         5.1125e-02,  2.6137e-03,  5.7395e-02, -6.2189e-03,  4.6410e-02,\n",
            "         5.1452e-02,  7.5749e-03,  9.9052e-02, -1.4697e-02, -1.1267e-02,\n",
            "        -2.4546e-02,  6.6772e-04,  2.8532e-02, -2.1448e-02,  3.8569e-02,\n",
            "         6.4753e-02,  4.7431e-02, -1.8105e-02, -9.9185e-04,  4.7560e-02,\n",
            "        -1.1760e-02, -1.7233e-03,  3.1337e-02, -4.8824e-02, -3.8882e-03,\n",
            "         2.6948e-02,  3.8179e-02,  4.1816e-02,  3.8382e-02, -4.2468e-03,\n",
            "         1.4916e-02,  1.0916e-03, -3.3332e-02,  2.7128e-02,  3.8336e-02,\n",
            "        -1.3542e-02,  1.1366e-02, -1.1887e-02,  1.9650e-02, -1.7301e-02,\n",
            "         7.4070e-02, -1.8700e-02,  7.3487e-02,  6.8274e-02, -2.0199e-02,\n",
            "         1.8647e-02,  2.6622e-02, -1.8233e-02,  8.3784e-02,  4.6528e-02,\n",
            "         2.4993e-02,  3.9501e-03,  2.9844e-02,  1.7486e-02,  5.3733e-02,\n",
            "         2.3581e-02,  3.4960e-02,  4.5680e-02,  1.8481e-02, -2.0081e-02,\n",
            "         4.7278e-03,  1.4380e-02, -2.5294e-02,  5.9331e-02,  3.9301e-02,\n",
            "         8.3386e-02, -2.9118e-02, -1.5454e-02,  5.4176e-02,  2.7780e-02,\n",
            "         6.4376e-03,  6.3490e-02,  5.5925e-02,  2.3940e-02,  1.4191e-02,\n",
            "         2.4270e-02, -1.5983e-02,  2.2883e-02,  3.3245e-02, -2.6566e-02,\n",
            "         8.9648e-03,  5.4897e-02, -1.5809e-02, -1.4639e-02,  2.1971e-02,\n",
            "         2.2488e-03, -1.1964e-02, -9.8448e-04, -3.4170e-02, -5.2094e-02,\n",
            "         5.8670e-02,  3.7140e-02, -3.2001e-02, -3.9349e-02,  9.8380e-03,\n",
            "        -3.2529e-03, -1.8789e-03,  7.2057e-02,  2.5986e-02, -4.1185e-02,\n",
            "         1.5307e-02,  7.6183e-02, -4.7074e-02,  5.8337e-02,  4.8005e-02,\n",
            "        -2.7574e-02,  2.8773e-02,  5.3229e-02,  1.8677e-02, -9.0448e-04,\n",
            "        -7.6605e-03, -3.1025e-02,  8.5792e-02,  1.1374e-02, -2.3276e-02,\n",
            "         4.8633e-02, -9.7346e-03,  2.3414e-02,  3.5679e-02,  3.6536e-02,\n",
            "         9.5141e-03,  4.3116e-02, -3.3438e-02,  8.6001e-03,  2.2900e-02,\n",
            "         8.3926e-02,  2.8694e-02,  6.5195e-02,  3.1192e-03,  7.0970e-02,\n",
            "         1.1029e-02, -8.2672e-03, -4.0779e-03, -6.3434e-03, -7.3167e-03,\n",
            "         1.1303e-02,  4.8216e-02, -1.2294e-02,  4.2479e-02,  3.5009e-02,\n",
            "        -1.7220e-02,  1.7744e-02, -1.3678e-02, -2.9339e-02,  2.3089e-03,\n",
            "        -2.7719e-02,  4.0636e-02,  3.5865e-02, -2.9291e-02, -3.4873e-02,\n",
            "         5.5871e-02,  2.8429e-02,  2.7480e-02, -4.2867e-02, -1.5186e-02,\n",
            "        -8.1632e-03,  6.0603e-02, -2.4147e-02,  3.6894e-03, -6.8360e-03,\n",
            "        -1.9672e-02,  2.8345e-02, -1.2904e-02, -2.3699e-02,  1.6436e-02,\n",
            "         5.1506e-03,  3.8420e-02,  4.2361e-02,  1.8605e-02,  3.0292e-03,\n",
            "        -1.3798e-02,  1.0122e-02, -2.1049e-02, -1.9596e-02, -4.8925e-04,\n",
            "        -4.2925e-02,  8.5485e-03,  2.3483e-02,  2.6992e-02, -4.3610e-02,\n",
            "         1.3755e-02,  1.9386e-02,  5.4587e-03, -5.3266e-02,  2.1930e-02,\n",
            "        -6.2456e-02,  2.3435e-02, -4.2850e-03,  2.2631e-02, -4.8200e-02,\n",
            "        -9.2831e-03,  3.2130e-03, -4.8031e-03,  1.1676e-02,  6.3059e-03,\n",
            "        -1.6016e-02, -7.4605e-04,  3.9605e-02, -3.8140e-03,  7.2573e-02,\n",
            "        -2.9415e-02, -6.0007e-03,  8.5075e-03,  6.1643e-03,  1.1459e-02,\n",
            "        -1.6879e-02,  8.7997e-03,  7.9403e-02,  1.3002e-02,  2.1485e-03,\n",
            "        -2.7415e-03, -1.7266e-02,  4.0669e-02,  1.7933e-02,  5.0262e-02,\n",
            "         9.5276e-03, -3.1968e-03, -5.8874e-02, -1.7764e-02,  9.3004e-02,\n",
            "         1.4693e-02,  5.7897e-02,  7.8011e-02,  3.3969e-02, -3.5023e-02,\n",
            "         1.7710e-02,  1.2708e-02,  3.3852e-02, -1.8920e-02, -1.0916e-02,\n",
            "         8.8929e-02,  3.0566e-04,  4.1442e-02, -3.6518e-02, -3.8947e-03,\n",
            "        -2.9497e-02,  9.5644e-02,  7.0006e-02,  1.7134e-03,  4.6009e-02,\n",
            "         3.0482e-02,  3.6199e-02,  2.9880e-02, -1.6645e-02, -3.3737e-02,\n",
            "         3.0946e-02, -3.0907e-02, -1.5649e-02,  5.5264e-02,  2.5306e-02,\n",
            "         1.2521e-02,  1.2930e-03,  5.9398e-02,  3.7124e-03,  6.5999e-02,\n",
            "        -1.5880e-02,  2.1751e-03,  6.3572e-02, -4.7099e-03,  1.9626e-02,\n",
            "         4.0648e-02,  1.6041e-02, -2.1732e-02,  3.3521e-02, -1.8346e-03,\n",
            "         4.5685e-02, -2.7292e-03, -1.2524e-02,  1.2831e-02, -1.2661e-02,\n",
            "        -1.7817e-02,  2.5559e-02,  4.4892e-02,  6.2831e-02, -3.5816e-02,\n",
            "         2.1908e-02,  5.2217e-02,  2.8222e-02,  1.4162e-02,  2.5952e-02,\n",
            "         4.0193e-02, -3.5979e-02, -8.4332e-03,  2.3171e-03, -2.1003e-02,\n",
            "         1.2323e-02,  2.0648e-02,  7.5133e-02,  4.6915e-02,  6.8122e-03,\n",
            "         1.5591e-02, -6.4467e-03,  5.2392e-03, -9.1509e-03,  1.1892e-02,\n",
            "        -4.5335e-02,  3.8515e-02,  2.1826e-03, -1.3132e-02, -4.2363e-02,\n",
            "         8.3548e-02, -9.1203e-05,  6.2627e-02, -3.7166e-02,  6.0473e-02,\n",
            "         5.2984e-02,  6.0474e-02,  1.0517e-02, -3.9152e-02, -2.2959e-03,\n",
            "         6.7629e-03,  4.2851e-02,  9.3094e-02, -5.7120e-02, -2.1933e-03,\n",
            "        -1.6739e-03,  6.4230e-02, -4.7198e-02,  1.5437e-02,  6.9245e-02,\n",
            "         4.4934e-02, -4.3655e-04, -1.3110e-02,  3.9606e-02,  1.1122e-02,\n",
            "         5.2774e-04, -1.2773e-02,  5.6033e-02,  3.8006e-02,  7.4347e-03,\n",
            "        -5.1437e-02,  4.5456e-02, -1.6462e-02,  1.6976e-02, -3.4718e-02,\n",
            "         2.1160e-02,  3.2150e-02,  1.2086e-02,  2.9001e-02,  6.0860e-02,\n",
            "         3.9336e-02, -9.7702e-03, -4.6573e-02, -1.9147e-02, -4.0067e-02,\n",
            "        -1.0905e-04, -4.8116e-02, -7.5664e-03,  2.1377e-04,  2.9954e-02,\n",
            "         6.8897e-03,  3.2220e-02,  4.6334e-02, -2.4569e-02, -4.7955e-02,\n",
            "        -5.1727e-02, -2.7968e-02,  5.6840e-03, -6.1278e-02,  2.2553e-02,\n",
            "        -3.3607e-02, -5.0603e-02, -1.6805e-02,  4.9888e-02,  1.6816e-02,\n",
            "        -3.2709e-02,  4.7909e-02,  3.0291e-02, -3.7651e-03,  7.2540e-03,\n",
            "         3.9032e-02, -2.6614e-02,  5.1931e-02, -2.5111e-02,  8.6197e-04,\n",
            "         3.3014e-02, -2.8570e-03, -4.1015e-02, -3.0444e-02, -4.6832e-03,\n",
            "         8.8646e-02,  4.1552e-02, -3.4816e-02, -8.0957e-03,  3.4475e-02,\n",
            "        -5.8698e-03,  6.7558e-03, -3.2556e-02,  3.1985e-02,  8.1945e-03,\n",
            "         2.6619e-02, -1.4567e-02,  3.4646e-02, -3.3915e-02,  1.4805e-02,\n",
            "         1.6138e-02, -5.0529e-03, -1.1423e-03,  1.5693e-03,  2.9244e-02,\n",
            "        -3.0914e-04, -1.8952e-02,  5.5368e-02,  6.1394e-02,  8.2387e-03,\n",
            "         3.1251e-02,  7.5037e-02,  1.2520e-02, -2.9966e-02, -9.6916e-03,\n",
            "         7.3375e-03,  1.8073e-02,  3.5290e-04,  2.8355e-02,  2.7584e-02,\n",
            "         2.7291e-03,  1.7577e-02, -2.7050e-02, -1.3165e-02,  6.4303e-02,\n",
            "         3.3110e-02,  4.1249e-02, -6.7340e-03,  4.5246e-02, -5.0685e-02,\n",
            "        -1.4956e-02,  8.3027e-03, -3.7628e-02, -1.2027e-02, -5.6459e-03])), ('4.weight', tensor([[-0.0072, -0.0906, -0.0814,  ...,  0.0022, -0.0617, -0.0501],\n",
            "        [ 0.0047, -0.0251, -0.0183,  ..., -0.0229,  0.0216, -0.0303],\n",
            "        [-0.0156, -0.0724, -0.0431,  ..., -0.0462,  0.0195,  0.0253],\n",
            "        ...,\n",
            "        [ 0.0072,  0.0381, -0.0431,  ..., -0.0292,  0.0516,  0.0673],\n",
            "        [ 0.0179, -0.0380, -0.0769,  ...,  0.0194, -0.1223,  0.0049],\n",
            "        [-0.0388, -0.0451, -0.0578,  ...,  0.0168, -0.0322, -0.1078]])), ('4.bias', tensor([-0.0504, -0.0282, -0.0113, -0.0790,  0.0474,  0.0350, -0.0506, -0.0660,\n",
            "         0.0542, -0.0202]))])\n",
            "loss 0.00010399818711448461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu9SePSqZAGf",
        "colab_type": "text"
      },
      "source": [
        "Проверка точности обработки 10.000 тестовых изображений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBri_8SrZHrD",
        "colab_type": "code",
        "outputId": "10701ccd-0be2-48de-d173-d5f02db110b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print('Точность: {}%'.format(100 * correct / total))"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Точность: 98.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNxUSIXnf-su",
        "colab_type": "text"
      },
      "source": [
        "Сохранение обученной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5DUi-ssgKn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, 'mnist_full.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkv22y3ugdXG",
        "colab_type": "text"
      },
      "source": [
        "Загрузка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN-u7-Flgf0f",
        "colab_type": "code",
        "outputId": "1baefb52-3368-43a5-c496-8fefde8971ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "model = torch.load('mnist_full.pt')\n",
        "model.eval()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=700, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=700, out_features=700, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=700, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFJz8jd9g5ee",
        "colab_type": "text"
      },
      "source": [
        "Визуальная проверка обученной модели. Код выводит четыре случайных изображения из датасета и указывает под ними соответствующие им классы (прогноз), которые заданы в списке classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSlE_c85hTue",
        "colab_type": "code",
        "outputId": "0e8b21ce-138f-45b3-ef7a-dbcfa8fbfbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "    \n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join('%10s' % classes[labels[j]] for j in range(10)))"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB4CAYAAADi1gmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noQldKaXihCZ0pZSKE5rQlVIqTvw/zubPkJyJMzQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         3          7          4          6          7          4          0          4          1          5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}